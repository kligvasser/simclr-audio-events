{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kligvasser/miniconda3/envs/audio-ssl/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import swifter\n",
    "import librosa\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from ast import literal_eval\n",
    "\n",
    "parent = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(parent)\n",
    "\n",
    "import data.misc as misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get metadatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = pd.read_csv(\n",
    "    f\"http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/class_labels_indices.csv\",\n",
    "    sep=\",\",\n",
    ")\n",
    "\n",
    "eval_df = pd.read_csv(\n",
    "    \"http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/eval_segments.csv\",\n",
    "    sep=\", \",\n",
    "    skiprows=3,\n",
    "    header=None,\n",
    "    names=[\"YTID\", \"start_seconds\", \"end_seconds\", \"positive_labels\"],\n",
    "    engine=\"python\",\n",
    ")\n",
    "\n",
    "balanced_train_df = pd.read_csv(\n",
    "    \"http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/balanced_train_segments.csv\",\n",
    "    sep=\", \",\n",
    "    skiprows=3,\n",
    "    header=None,\n",
    "    names=[\"YTID\", \"start_seconds\", \"end_seconds\", \"positive_labels\"],\n",
    "    engine=\"python\",\n",
    ")\n",
    "\n",
    "unbalanced_train_df = pd.read_csv(\n",
    "    \"http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/unbalanced_train_segments.csv\",\n",
    "    sep=\", \",\n",
    "    skiprows=3,\n",
    "    header=None,\n",
    "    names=[\"YTID\", \"start_seconds\", \"end_seconds\", \"positive_labels\"],\n",
    "    engine=\"python\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df[\"positive_labels\"] = eval_df[\"positive_labels\"].apply(literal_eval)\n",
    "balanced_train_df[\"positive_labels\"] = balanced_train_df[\"positive_labels\"].apply(literal_eval)\n",
    "unbalanced_train_df[\"positive_labels\"] = unbalanced_train_df[\"positive_labels\"].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_class_info(row):\n",
    "    positive_labels = row[\"positive_labels\"].split(\",\")\n",
    "    labels_index, labels_name = list(), list()\n",
    "    for label_code in positive_labels:\n",
    "        label_index = class_code_to_index.index(label_code)\n",
    "        label_name = class_code_to_name[label_index]\n",
    "        labels_index.append(label_index)\n",
    "        labels_name.append(label_name)\n",
    "\n",
    "    return pd.Series([labels_index, labels_name], index=['labels_index', 'labels_name'])\n",
    "\n",
    "\n",
    "class_code_to_index = list(class_df[\"mid\"].values)\n",
    "class_code_to_name = list(class_df[\"display_name\"].values)\n",
    "\n",
    "eval_df_ = eval_df.apply(_extract_class_info, axis=1)\n",
    "eval_df = pd.concat([eval_df, eval_df_], axis=1)\n",
    "\n",
    "balanced_train_df_ = balanced_train_df.apply(_extract_class_info, axis=1)\n",
    "balanced_train_df = pd.concat([balanced_train_df, balanced_train_df_], axis=1)\n",
    "\n",
    "unbalanced_train_df_ = unbalanced_train_df.apply(_extract_class_info, axis=1)\n",
    "unbalanced_train_df = pd.concat([unbalanced_train_df, unbalanced_train_df_], axis=1)\n",
    "\n",
    "metadata_path = \"/storage11/datasets/audioset/metadata/\"\n",
    "misc.save_df(class_df, os.path.join(metadata_path, \"class_labels_indices.csv\"))\n",
    "misc.save_df(eval_df, os.path.join(metadata_path, \"eval_segments.csv\"))\n",
    "misc.save_df(balanced_train_df, os.path.join(metadata_path, \"balanced_train_segments.csv\"))\n",
    "misc.save_df(unbalanced_train_df, os.path.join(metadata_path, \"unbalanced_train_segments.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YTID</th>\n",
       "      <th>start_seconds</th>\n",
       "      <th>end_seconds</th>\n",
       "      <th>positive_labels</th>\n",
       "      <th>labels_index</th>\n",
       "      <th>labels_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--4gqARaEJE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>/m/068hy,/m/07q6cd_,/m/0bt9lr,/m/0jbk</td>\n",
       "      <td>[73, 361, 74, 72]</td>\n",
       "      <td>[Domestic animals, pets, Squeak, Dog, Animal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--BfvyPmVMo</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>/m/03l9g</td>\n",
       "      <td>[419]</td>\n",
       "      <td>[Hammer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--U7joUcTCo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>/m/01b_21</td>\n",
       "      <td>[47]</td>\n",
       "      <td>[Cough]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--i-y1v8Hy8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>/m/04rlf,/m/09x0r,/t/dd00004,/t/dd00005</td>\n",
       "      <td>[137, 0, 33, 34]</td>\n",
       "      <td>[Music, Speech, Female singing, Child singing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0BIyqJj9ZU</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>/m/07rgt08,/m/07sq110,/t/dd00001</td>\n",
       "      <td>[21, 20, 17]</td>\n",
       "      <td>[Chuckle, chortle, Belly laugh, Baby laughter]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          YTID  start_seconds  end_seconds  \\\n",
       "0  --4gqARaEJE            0.0         10.0   \n",
       "1  --BfvyPmVMo           20.0         30.0   \n",
       "2  --U7joUcTCo            0.0         10.0   \n",
       "3  --i-y1v8Hy8            0.0          9.0   \n",
       "4  -0BIyqJj9ZU           30.0         40.0   \n",
       "\n",
       "                           positive_labels       labels_index  \\\n",
       "0    /m/068hy,/m/07q6cd_,/m/0bt9lr,/m/0jbk  [73, 361, 74, 72]   \n",
       "1                                 /m/03l9g              [419]   \n",
       "2                                /m/01b_21               [47]   \n",
       "3  /m/04rlf,/m/09x0r,/t/dd00004,/t/dd00005   [137, 0, 33, 34]   \n",
       "4         /m/07rgt08,/m/07sq110,/t/dd00001       [21, 20, 17]   \n",
       "\n",
       "                                      labels_name  \n",
       "0   [Domestic animals, pets, Squeak, Dog, Animal]  \n",
       "1                                        [Hammer]  \n",
       "2                                         [Cough]  \n",
       "3  [Music, Speech, Female singing, Child singing]  \n",
       "4  [Chuckle, chortle, Belly laugh, Baby laughter]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataframes for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval-dataframe...\n",
      " Cleaning corrupted files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 20371/20371 [00:04<00:00, 4192.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extending multi label to one hot\n",
      "Balanced-dataframe...\n",
      " Cleaning corrupted files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 22160/22160 [00:05<00:00, 3995.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extending multi label to one hot\n",
      "Unbalanced-dataframe...\n",
      " Cleaning corrupted files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 50000/50000 [00:12<00:00, 3929.42it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:12<00:00, 4004.67it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:12<00:00, 4019.82it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:12<00:00, 3976.68it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:16<00:00, 3040.59it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:15<00:00, 3242.58it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:15<00:00, 3229.22it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:12<00:00, 4033.79it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:15<00:00, 3277.05it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:18<00:00, 2705.65it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:12<00:00, 3993.05it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:15<00:00, 3266.09it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3341.44it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3349.28it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:15<00:00, 3313.17it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3346.59it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:15<00:00, 3304.63it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3355.14it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:15<00:00, 3329.30it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3360.70it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3350.59it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3349.34it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3338.39it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:15<00:00, 3333.27it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3360.66it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3366.08it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3381.39it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3412.99it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3395.84it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3340.52it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:12<00:00, 4070.90it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:15<00:00, 3304.71it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3353.33it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3404.76it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3408.21it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3339.15it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3423.51it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3376.89it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:14<00:00, 3409.92it/s]\n",
      "Pandas Apply: 100%|██████████| 50000/50000 [00:17<00:00, 2835.86it/s]\n",
      "Pandas Apply: 100%|██████████| 41789/41789 [00:10<00:00, 4085.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extending multi label to one hot\n"
     ]
    }
   ],
   "source": [
    "CLASSES = list(range(527))\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "def process_audio_file(path):\n",
    "    try:\n",
    "        audio, _ = librosa.load(path, sr=None, mono=True)\n",
    "        if audio.std() > 0:\n",
    "            return path\n",
    "        else:\n",
    "            print(f\"Removing {path} due to zero standard deviation.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Removing {path} due to error: {e}\")\n",
    "    os.remove(path)\n",
    "    return None\n",
    "\n",
    "\n",
    "def clean_audio_files(audio_paths, max_workers=32):\n",
    "    valid_audio_paths = list()\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_path = {executor.submit(process_audio_file, path): path for path in audio_paths}\n",
    "        for future in as_completed(future_to_path):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                valid_audio_paths.append(result)\n",
    "\n",
    "    return valid_audio_paths\n",
    "\n",
    "\n",
    "def extend_multi_label_to_one_hot(df, column_name):\n",
    "    print(\" Extending multi label to one hot\")\n",
    "    mlb = MultiLabelBinarizer(classes=CLASSES)\n",
    "    mlb.fit(df[column_name])\n",
    "    one_hot_encoded = mlb.transform(df[column_name])\n",
    "    one_hot_df = pd.DataFrame(data=one_hot_encoded, columns=mlb.classes_)\n",
    "    df = pd.concat([df, one_hot_df], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_corrupted(root_path):\n",
    "    print(\" Cleaning corrupted files...\")\n",
    "    audios = misc.get_file_list(root_path)\n",
    "    _ = clean_audio_files(audios)\n",
    "\n",
    "\n",
    "def build_database_df(df, root_path, ext=\".wav\", chunk_size=50000):\n",
    "    def _extract_audio_info(row):\n",
    "        audio_id = row[\"YTID\"]\n",
    "        path = os.path.join(root_path, audio_id + ext)\n",
    "        relative = path.replace(root_path, \"\")\n",
    "        basename = os.path.basename(path)\n",
    "        length_seconds = row[\"end_seconds\"] - row[\"start_seconds\"]\n",
    "        exists = os.path.exists(path)\n",
    "\n",
    "        return pd.Series(\n",
    "            [\n",
    "                path,\n",
    "                relative,\n",
    "                basename,\n",
    "                length_seconds,\n",
    "                exists,\n",
    "            ],\n",
    "            index=[\n",
    "                \"path\",\n",
    "                \"relative\",\n",
    "                \"basename\",\n",
    "                \"length_seconds\",\n",
    "                \"exists\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    if df.shape[0] < chunk_size:\n",
    "        df_ = df.swifter.apply(_extract_audio_info, axis=1)\n",
    "        df = pd.concat([df, df_], axis=1)\n",
    "    else:\n",
    "        chunks = list()\n",
    "        for start in range(0, df.shape[0], chunk_size):\n",
    "            end = start + chunk_size\n",
    "            df_slice = df.iloc[start:end]\n",
    "            df_slice_ = df_slice.swifter.apply(_extract_audio_info, axis=1)\n",
    "            df_slice = pd.concat([df_slice, df_slice_], axis=1)\n",
    "            chunks.append(df_slice)\n",
    "        df = pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "    df = df[df[\"exists\"] == True].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"Eval-dataframe...\")\n",
    "root_path = \"/storage11/datasets/audioset/audios/eval/\"\n",
    "clean_corrupted(root_path)\n",
    "records_eval_df = build_database_df(eval_df, root_path)\n",
    "misc.save_df(records_eval_df, os.path.join(root_path, \"records.pkl\"))\n",
    "records_eval_df = extend_multi_label_to_one_hot(records_eval_df, \"labels_index\")\n",
    "misc.save_df(records_eval_df, os.path.join(root_path, \"records-hot1.pkl\"))\n",
    "\n",
    "\n",
    "print(\"Balanced-dataframe...\")\n",
    "clean_corrupted(root_path)\n",
    "root_path = \"/storage11/datasets/audioset/audios/balanced_train/\"\n",
    "records_balanced_train_df = build_database_df(balanced_train_df, root_path)\n",
    "misc.save_df(records_balanced_train_df, os.path.join(root_path, \"records.pkl\"))\n",
    "records_balanced_train_df = extend_multi_label_to_one_hot(records_balanced_train_df, \"labels_index\")\n",
    "misc.save_df(records_balanced_train_df, os.path.join(root_path, \"records-hot1.pkl\"))\n",
    "\n",
    "\n",
    "print(\"Unbalanced-dataframe...\")\n",
    "clean_corrupted(root_path)\n",
    "root_path = \"/storage11/datasets/audioset/audios/unbalanced_train/\"\n",
    "records_unbalanced_train_df = build_database_df(unbalanced_train_df, root_path)\n",
    "misc.save_df(records_unbalanced_train_df, os.path.join(root_path, \"records.pkl\"))\n",
    "records_unbalanced_train_df = extend_multi_label_to_one_hot(\n",
    "    records_unbalanced_train_df, \"labels_index\"\n",
    ")\n",
    "misc.save_df(records_unbalanced_train_df, os.path.join(root_path, \"records-hot1.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_balanced_train_df[\"source\"] = \"balanced_train\"\n",
    "records_unbalanced_train_df[\"source\"] = \"unbalanced_train\"\n",
    "df = pd.concat([records_balanced_train_df, records_unbalanced_train_df], ignore_index=True)\n",
    "df = df.drop([\"relative\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fix_relative(row):\n",
    "    return row[\"path\"].replace(root_path, \"\")\n",
    "\n",
    "\n",
    "root_path = \"/storage11/datasets/audioset/audios/\"\n",
    "df[\"relative\"] = df.apply(_fix_relative, axis=1)\n",
    "misc.save_df(df, os.path.join(root_path, \"train-full-records-hot1.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YTID</th>\n",
       "      <th>start_seconds</th>\n",
       "      <th>end_seconds</th>\n",
       "      <th>positive_labels</th>\n",
       "      <th>labels_index</th>\n",
       "      <th>labels_name</th>\n",
       "      <th>path</th>\n",
       "      <th>basename</th>\n",
       "      <th>length_seconds</th>\n",
       "      <th>exists</th>\n",
       "      <th>...</th>\n",
       "      <th>519</th>\n",
       "      <th>520</th>\n",
       "      <th>521</th>\n",
       "      <th>522</th>\n",
       "      <th>523</th>\n",
       "      <th>524</th>\n",
       "      <th>525</th>\n",
       "      <th>526</th>\n",
       "      <th>source</th>\n",
       "      <th>relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--PJHxphWEs</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>/m/09x0r,/t/dd00088</td>\n",
       "      <td>[0, 451]</td>\n",
       "      <td>[Speech, Gush]</td>\n",
       "      <td>/storage11/datasets/audioset/audios/balanced_t...</td>\n",
       "      <td>--PJHxphWEs.wav</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>balanced_train</td>\n",
       "      <td>balanced_train/--PJHxphWEs.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--aE2O5G5WE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>/m/03fwl,/m/04rlf,/m/09x0r</td>\n",
       "      <td>[95, 137, 0]</td>\n",
       "      <td>[Goat, Music, Speech]</td>\n",
       "      <td>/storage11/datasets/audioset/audios/balanced_t...</td>\n",
       "      <td>--aE2O5G5WE.wav</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>balanced_train</td>\n",
       "      <td>balanced_train/--aE2O5G5WE.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--aaILOrkII</td>\n",
       "      <td>200.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>/m/032s66,/m/073cg4</td>\n",
       "      <td>[427, 431]</td>\n",
       "      <td>[Gunshot, gunfire, Cap gun]</td>\n",
       "      <td>/storage11/datasets/audioset/audios/balanced_t...</td>\n",
       "      <td>--aaILOrkII.wav</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>balanced_train</td>\n",
       "      <td>balanced_train/--aaILOrkII.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--ekDLDTUXA</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>/m/015lz1,/m/07pws3f</td>\n",
       "      <td>[27, 466]</td>\n",
       "      <td>[Singing, Bang]</td>\n",
       "      <td>/storage11/datasets/audioset/audios/balanced_t...</td>\n",
       "      <td>--ekDLDTUXA.wav</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>balanced_train</td>\n",
       "      <td>balanced_train/--ekDLDTUXA.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0DLPzsiXXE</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>/m/04rlf,/m/07qwdck</td>\n",
       "      <td>[137, 482]</td>\n",
       "      <td>[Music, Ping]</td>\n",
       "      <td>/storage11/datasets/audioset/audios/balanced_t...</td>\n",
       "      <td>-0DLPzsiXXE.wav</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>balanced_train</td>\n",
       "      <td>balanced_train/-0DLPzsiXXE.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 539 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          YTID  start_seconds  end_seconds             positive_labels  \\\n",
       "0  --PJHxphWEs           30.0         40.0         /m/09x0r,/t/dd00088   \n",
       "1  --aE2O5G5WE            0.0         10.0  /m/03fwl,/m/04rlf,/m/09x0r   \n",
       "2  --aaILOrkII          200.0        210.0         /m/032s66,/m/073cg4   \n",
       "3  --ekDLDTUXA           30.0         40.0        /m/015lz1,/m/07pws3f   \n",
       "4  -0DLPzsiXXE           30.0         40.0         /m/04rlf,/m/07qwdck   \n",
       "\n",
       "   labels_index                  labels_name  \\\n",
       "0      [0, 451]               [Speech, Gush]   \n",
       "1  [95, 137, 0]        [Goat, Music, Speech]   \n",
       "2    [427, 431]  [Gunshot, gunfire, Cap gun]   \n",
       "3     [27, 466]              [Singing, Bang]   \n",
       "4    [137, 482]                [Music, Ping]   \n",
       "\n",
       "                                                path         basename  \\\n",
       "0  /storage11/datasets/audioset/audios/balanced_t...  --PJHxphWEs.wav   \n",
       "1  /storage11/datasets/audioset/audios/balanced_t...  --aE2O5G5WE.wav   \n",
       "2  /storage11/datasets/audioset/audios/balanced_t...  --aaILOrkII.wav   \n",
       "3  /storage11/datasets/audioset/audios/balanced_t...  --ekDLDTUXA.wav   \n",
       "4  /storage11/datasets/audioset/audios/balanced_t...  -0DLPzsiXXE.wav   \n",
       "\n",
       "   length_seconds  exists  ...  519  520  521  522  523  524  525  526  \\\n",
       "0            10.0    True  ...    0    0    0    0    0    0    0    0   \n",
       "1            10.0    True  ...    0    0    0    0    0    0    0    0   \n",
       "2            10.0    True  ...    0    0    0    0    0    0    0    0   \n",
       "3            10.0    True  ...    0    0    0    0    0    0    0    0   \n",
       "4            10.0    True  ...    0    0    0    0    0    0    0    0   \n",
       "\n",
       "           source                        relative  \n",
       "0  balanced_train  balanced_train/--PJHxphWEs.wav  \n",
       "1  balanced_train  balanced_train/--aE2O5G5WE.wav  \n",
       "2  balanced_train  balanced_train/--aaILOrkII.wav  \n",
       "3  balanced_train  balanced_train/--ekDLDTUXA.wav  \n",
       "4  balanced_train  balanced_train/-0DLPzsiXXE.wav  \n",
       "\n",
       "[5 rows x 539 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
